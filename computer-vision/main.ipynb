{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b91fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f7757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jose/miniconda3/envs/jaguar/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T\n",
    "from pytorch_metric_learning import losses, samplers\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timm.data import resolve_data_config\n",
    "import timm\n",
    "from transformers import AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2808c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get best available device for MacOS\"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using Apple Silicon GPU (MPS)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2837ef",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25487212",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaguarTrainDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Create label mapping\n",
    "        unique_jaguars = sorted(self.df['ground_truth'].unique())\n",
    "        self.label_map = {name: idx for idx, name in enumerate(unique_jaguars)}\n",
    "        self.num_classes = len(unique_jaguars)\n",
    "        \n",
    "        print(f\"Found {self.num_classes} unique jaguars\")\n",
    "        print(f\"Total training images: {len(self.df)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.img_dir / row['filename']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.label_map[row['ground_truth']]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class JaguarTestDataset(Dataset):\n",
    "    \"\"\"Dataset for extracting embeddings from test images\"\"\"\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = Path(test_dir)\n",
    "        # Get all test images\n",
    "        self.image_files = sorted(self.test_dir.glob('*.png'))\n",
    "        self.transform = transform\n",
    "        \n",
    "        print(f\"Found {len(self.image_files)} test images\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, img_path.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a11f3b",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bf4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_stats(model_name='dinov2_vitb14'):\n",
    "    \n",
    "    # Map model names to Hugging Face identifiers\n",
    "    model_map = {\n",
    "        'dinov2_vits14': 'facebook/dinov2-small',\n",
    "        'dinov2_vitb14': 'facebook/dinov2-base',\n",
    "        'dinov2_vitl14': 'facebook/dinov2-large',\n",
    "    }\n",
    "    \n",
    "    hf_name = model_map.get(model_name, 'facebook/dinov2-base')\n",
    "    \n",
    "    print(f\"Loading normalization from {hf_name}...\")\n",
    "    processor = AutoImageProcessor.from_pretrained(hf_name)\n",
    "    \n",
    "    mean = processor.image_mean\n",
    "    std = processor.image_std\n",
    "    \n",
    "    print(f\"  mean: {mean}\")\n",
    "    print(f\"  std: {std}\")\n",
    "    \n",
    "    return {\n",
    "        'mean': mean,\n",
    "        'std': std\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da403107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(img_size=224, model_name='dinov2_vitb14'):\n",
    "    \"\"\"\n",
    "    Create train and test transforms with model-specific normalization.\n",
    "    \n",
    "    Args:\n",
    "        img_size: Target image size (default: 224)\n",
    "        model_name: Name of the pretrained model to match normalization\n",
    "    \n",
    "    Returns:\n",
    "        train_transform, test_transform\n",
    "    \"\"\"\n",
    "    # Load normalization stats from model\n",
    "    norm_stats = get_normalization_stats(model_name)\n",
    "    \n",
    "    train_transform = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=15),\n",
    "        T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "        T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=norm_stats['mean'], std=norm_stats['std'])\n",
    "    ])\n",
    "    \n",
    "    test_transform = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=norm_stats['mean'], std=norm_stats['std'])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, test_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c61c9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0605dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaguarReIDModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=512, backbone='dinov2'):\n",
    "        super().__init__()\n",
    "        \n",
    "        if backbone == 'dinov2':\n",
    "            # DINOv2 ViT-Base\n",
    "            print(\"Loading DINOv2 ViT-Base...\")\n",
    "            self.backbone = torch.hub.load('facebookresearch/dinov2', \n",
    "                                          'dinov2_vitb14')\n",
    "            backbone_dim = 768\n",
    "        elif backbone == 'dinov2_small':\n",
    "            print(\"Loading DINOv2 ViT-Small (faster for CPU/MPS)...\")\n",
    "            self.backbone = torch.hub.load('facebookresearch/dinov2', \n",
    "                                          'dinov2_vits14')\n",
    "            backbone_dim = 384\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown backbone: {backbone}\")\n",
    "        \n",
    "        # Projection head to desired embedding dimension\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(backbone_dim, embedding_dim),\n",
    "            nn.BatchNorm1d(embedding_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        embeddings = self.projection(features)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ace44",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fc0867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_csv, train_dir, num_epochs=20, batch_size=32, \n",
    "                embedding_dim=512, lr=1e-4, device='cpu'):\n",
    "    \n",
    "    # Setup transforms\n",
    "    train_transform, _ = get_transforms()\n",
    "    \n",
    "    # Create dataset\n",
    "    train_dataset = JaguarTrainDataset(train_csv, train_dir, train_transform)\n",
    "    num_classes = train_dataset.num_classes\n",
    "    \n",
    "    # Create labels array for sampler\n",
    "    labels = [train_dataset.label_map[row['ground_truth']] \n",
    "              for _, row in train_dataset.df.iterrows()]\n",
    "    \n",
    "    # Balanced sampler (4 images per jaguar per batch)\n",
    "    sampler = samplers.MPerClassSampler(\n",
    "        labels=labels,\n",
    "        m=4,  # 4 images per class\n",
    "        length_before_new_iter=len(train_dataset)\n",
    "    )\n",
    "    \n",
    "    # Reduce num_workers for MacOS (can cause issues with MPS)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,\n",
    "        num_workers=0,  # MacOS: use 0 to avoid multiprocessing issues\n",
    "        pin_memory=False  # MPS doesn't support pin_memory\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = JaguarReIDModel(embedding_dim=embedding_dim, \n",
    "                           backbone='dinov2_small').to(device)  # Use small for speed\n",
    "    \n",
    "    # ArcFace loss\n",
    "    loss_func = losses.ArcFaceLoss(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=embedding_dim,\n",
    "        margin=28.6,  # degrees\n",
    "        scale=64\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer for both model and loss function\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters(), 'lr': lr},\n",
    "        {'params': loss_func.parameters(), 'lr': lr}\n",
    "    ])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_epochs\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for images, labels_batch in pbar:\n",
    "            images = images.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            embeddings = model(images)\n",
    "            loss = loss_func(embeddings, labels_batch)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Avg Loss: {avg_loss:.4f}, LR: {current_lr:.6f}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc16a10",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d9dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_embeddings(model, test_dir, device='cpu'):\n",
    "    \"\"\"Extract embeddings for all test images\"\"\"\n",
    "    _, test_transform = get_transforms()\n",
    "    \n",
    "    test_dataset = JaguarTestDataset(test_dir, test_transform)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,  # Smaller batch for MacOS\n",
    "        shuffle=False,\n",
    "        num_workers=0,  # MacOS: avoid multiprocessing\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    embeddings_dict = {}\n",
    "    \n",
    "    print(\"\\nExtracting test embeddings...\")\n",
    "    with torch.no_grad():\n",
    "        for images, filenames in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            embeddings = model(images)\n",
    "            \n",
    "            # Normalize embeddings for cosine similarity\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "            \n",
    "            for emb, fname in zip(embeddings, filenames):\n",
    "                embeddings_dict[fname] = emb.cpu().numpy()\n",
    "    \n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "def create_submission(embeddings_dict, test_csv, output_path):\n",
    "    \"\"\"Create submission file from embeddings\"\"\"\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    \n",
    "    print(\"\\nComputing similarities...\")\n",
    "    similarities = []\n",
    "    \n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "        query_emb = embeddings_dict[row['query_image']]\n",
    "        gallery_emb = embeddings_dict[row['gallery_image']]\n",
    "        \n",
    "        # Cosine similarity (already normalized, so just dot product)\n",
    "        sim = np.dot(query_emb, gallery_emb)\n",
    "        \n",
    "        # Map from [-1, 1] to [0, 1]\n",
    "        sim = (sim + 1) / 2\n",
    "        \n",
    "        # Clip to ensure valid range\n",
    "        sim = np.clip(sim, 0.0, 1.0)\n",
    "        \n",
    "        similarities.append(sim)\n",
    "    \n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        'row_id': test_df['row_id'],\n",
    "        'similarity': similarities\n",
    "    })\n",
    "    \n",
    "    # Validate\n",
    "    assert len(submission) == 137270, f\"Wrong number of rows: {len(submission)}\"\n",
    "    assert (submission['similarity'] >= 0).all(), \"Found negative values\"\n",
    "    assert (submission['similarity'] <= 1).all(), \"Found values > 1\"\n",
    "    \n",
    "    # Save\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Submission saved to {output_path}\")\n",
    "    print(f\"  Rows: {len(submission):,}\")\n",
    "    print(f\"  Similarity range: [{submission['similarity'].min():.4f}, {submission['similarity'].max():.4f}]\")\n",
    "    print(f\"  Similarity mean: {submission['similarity'].mean():.4f}\")\n",
    "    \n",
    "    return submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f159b2",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6865b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU (MPS)\n",
      "Loading normalization from facebook/dinov2-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `BitImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  mean: [0.485, 0.456, 0.406]\n",
      "  std: [0.229, 0.224, 0.225]\n",
      "Found 31 unique jaguars\n",
      "Total training images: 1895\n",
      "Loading DINOv2 ViT-Small (faster for CPU/MPS)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jose/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/Users/jose/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/Users/jose/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/Users/jose/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 72 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/72:   0%|          | 0/59 [00:00<?, ?it/s]/Users/jose/miniconda3/envs/jaguar/lib/python3.11/site-packages/torch/nn/functional.py:4046: UserWarning: The operator 'aten::upsample_bicubic2d.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)\n",
      "Epoch 1/72: 100%|██████████| 59/59 [05:49<00:00,  5.93s/it, loss=34.5937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72, Avg Loss: 34.6675, LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/72: 100%|██████████| 59/59 [06:35<00:00,  6.71s/it, loss=36.1005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/72, Avg Loss: 33.7507, LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/72: 100%|██████████| 59/59 [06:54<00:00,  7.03s/it, loss=34.9721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/72, Avg Loss: 33.4661, LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/72: 100%|██████████| 59/59 [06:54<00:00,  7.03s/it, loss=36.0948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/72, Avg Loss: 33.1532, LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/72: 100%|██████████| 59/59 [07:02<00:00,  7.16s/it, loss=35.7875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/72, Avg Loss: 32.6407, LR: 0.000099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/72: 100%|██████████| 59/59 [06:51<00:00,  6.98s/it, loss=35.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/72, Avg Loss: 32.3745, LR: 0.000099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/72: 100%|██████████| 59/59 [06:44<00:00,  6.86s/it, loss=36.0758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/72, Avg Loss: 32.1125, LR: 0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/72: 100%|██████████| 59/59 [06:49<00:00,  6.93s/it, loss=36.4198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/72, Avg Loss: 31.8071, LR: 0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/72: 100%|██████████| 59/59 [06:46<00:00,  6.88s/it, loss=38.5992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/72, Avg Loss: 31.3730, LR: 0.000097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/72: 100%|██████████| 59/59 [06:47<00:00,  6.91s/it, loss=40.3009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/72, Avg Loss: 31.0530, LR: 0.000096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/72: 100%|██████████| 59/59 [06:41<00:00,  6.81s/it, loss=39.6079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/72, Avg Loss: 31.0971, LR: 0.000095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/72: 100%|██████████| 59/59 [06:47<00:00,  6.90s/it, loss=37.4759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/72, Avg Loss: 30.4863, LR: 0.000094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/72: 100%|██████████| 59/59 [06:55<00:00,  7.04s/it, loss=38.5848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/72, Avg Loss: 29.9937, LR: 0.000093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/72: 100%|██████████| 59/59 [06:47<00:00,  6.91s/it, loss=35.4070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/72, Avg Loss: 30.1999, LR: 0.000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/72: 100%|██████████| 59/59 [06:43<00:00,  6.84s/it, loss=29.8202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/72, Avg Loss: 29.0646, LR: 0.000091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/72: 100%|██████████| 59/59 [06:45<00:00,  6.87s/it, loss=37.2507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/72, Avg Loss: 29.4650, LR: 0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/72: 100%|██████████| 59/59 [06:43<00:00,  6.84s/it, loss=38.3667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/72, Avg Loss: 28.3412, LR: 0.000088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/72: 100%|██████████| 59/59 [06:42<00:00,  6.83s/it, loss=40.0969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/72, Avg Loss: 27.8032, LR: 0.000087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/72: 100%|██████████| 59/59 [06:36<00:00,  6.73s/it, loss=38.4236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/72, Avg Loss: 28.1680, LR: 0.000085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/72: 100%|██████████| 59/59 [06:34<00:00,  6.69s/it, loss=40.5200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/72, Avg Loss: 26.7222, LR: 0.000084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/72: 100%|██████████| 59/59 [06:31<00:00,  6.63s/it, loss=42.6841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/72, Avg Loss: 26.6077, LR: 0.000082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/72: 100%|██████████| 59/59 [06:25<00:00,  6.53s/it, loss=44.1351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/72, Avg Loss: 25.5374, LR: 0.000080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/72: 100%|██████████| 59/59 [06:31<00:00,  6.64s/it, loss=40.5112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/72, Avg Loss: 24.6192, LR: 0.000079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/72: 100%|██████████| 59/59 [06:30<00:00,  6.62s/it, loss=48.6351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/72, Avg Loss: 23.5902, LR: 0.000077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/72: 100%|██████████| 59/59 [06:31<00:00,  6.63s/it, loss=37.6328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/72, Avg Loss: 24.1756, LR: 0.000075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/72: 100%|██████████| 59/59 [06:32<00:00,  6.65s/it, loss=49.7298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/72, Avg Loss: 23.5879, LR: 0.000073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/72: 100%|██████████| 59/59 [06:29<00:00,  6.60s/it, loss=46.6920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/72, Avg Loss: 22.6759, LR: 0.000071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/72: 100%|██████████| 59/59 [06:25<00:00,  6.54s/it, loss=47.0831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/72, Avg Loss: 21.6139, LR: 0.000069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/72: 100%|██████████| 59/59 [06:25<00:00,  6.54s/it, loss=35.2645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/72, Avg Loss: 20.5296, LR: 0.000067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/72: 100%|██████████| 59/59 [06:23<00:00,  6.50s/it, loss=46.3532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/72, Avg Loss: 19.5197, LR: 0.000065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/72: 100%|██████████| 59/59 [06:20<00:00,  6.44s/it, loss=48.9032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/72, Avg Loss: 18.4750, LR: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/72: 100%|██████████| 59/59 [06:17<00:00,  6.40s/it, loss=48.9858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/72, Avg Loss: 18.2474, LR: 0.000061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/72: 100%|██████████| 59/59 [06:19<00:00,  6.43s/it, loss=45.3962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/72, Avg Loss: 17.1411, LR: 0.000059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/72: 100%|██████████| 59/59 [06:23<00:00,  6.50s/it, loss=44.7477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/72, Avg Loss: 15.8888, LR: 0.000057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/72: 100%|██████████| 59/59 [06:21<00:00,  6.47s/it, loss=47.7322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/72, Avg Loss: 15.2700, LR: 0.000054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/72: 100%|██████████| 59/59 [06:23<00:00,  6.50s/it, loss=48.8119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/72, Avg Loss: 14.5884, LR: 0.000052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/72: 100%|██████████| 59/59 [06:22<00:00,  6.48s/it, loss=44.5875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/72, Avg Loss: 13.1453, LR: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/72: 100%|██████████| 59/59 [06:28<00:00,  6.58s/it, loss=51.8622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/72, Avg Loss: 12.7343, LR: 0.000048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/72: 100%|██████████| 59/59 [06:28<00:00,  6.58s/it, loss=48.0027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/72, Avg Loss: 11.2747, LR: 0.000046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/72: 100%|██████████| 59/59 [06:23<00:00,  6.49s/it, loss=38.1376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/72, Avg Loss: 11.4815, LR: 0.000043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/72: 100%|██████████| 59/59 [06:34<00:00,  6.68s/it, loss=47.3524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/72, Avg Loss: 10.4309, LR: 0.000041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/72: 100%|██████████| 59/59 [06:40<00:00,  6.79s/it, loss=37.6674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/72, Avg Loss: 8.7014, LR: 0.000039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/72: 100%|██████████| 59/59 [06:34<00:00,  6.69s/it, loss=36.5975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/72, Avg Loss: 8.5479, LR: 0.000037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/72: 100%|██████████| 59/59 [06:32<00:00,  6.66s/it, loss=43.3312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/72, Avg Loss: 8.0330, LR: 0.000035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/72: 100%|██████████| 59/59 [06:22<00:00,  6.47s/it, loss=51.0538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/72, Avg Loss: 7.3076, LR: 0.000033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/72: 100%|██████████| 59/59 [06:24<00:00,  6.52s/it, loss=45.2159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/72, Avg Loss: 7.3548, LR: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/72: 100%|██████████| 59/59 [06:19<00:00,  6.43s/it, loss=43.2104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/72, Avg Loss: 6.8414, LR: 0.000029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/72: 100%|██████████| 59/59 [06:23<00:00,  6.50s/it, loss=48.3427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/72, Avg Loss: 6.6239, LR: 0.000027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/72: 100%|██████████| 59/59 [06:26<00:00,  6.55s/it, loss=41.6148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/72, Avg Loss: 5.7467, LR: 0.000025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/72: 100%|██████████| 59/59 [06:21<00:00,  6.47s/it, loss=46.3461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/72, Avg Loss: 5.9359, LR: 0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/72: 100%|██████████| 59/59 [06:28<00:00,  6.58s/it, loss=48.2698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/72, Avg Loss: 6.0674, LR: 0.000021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/72: 100%|██████████| 59/59 [06:30<00:00,  6.62s/it, loss=42.4357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/72, Avg Loss: 5.0582, LR: 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/72: 100%|██████████| 59/59 [06:22<00:00,  6.48s/it, loss=43.8508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/72, Avg Loss: 5.3627, LR: 0.000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/72: 100%|██████████| 59/59 [06:26<00:00,  6.56s/it, loss=41.6741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/72, Avg Loss: 4.4060, LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/72: 100%|██████████| 59/59 [06:19<00:00,  6.44s/it, loss=36.5710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/72, Avg Loss: 4.0534, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/72: 100%|██████████| 59/59 [06:17<00:00,  6.39s/it, loss=45.4916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/72, Avg Loss: 4.4583, LR: 0.000013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/72: 100%|██████████| 59/59 [06:13<00:00,  6.33s/it, loss=49.8329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/72, Avg Loss: 3.9696, LR: 0.000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/72: 100%|██████████| 59/59 [06:19<00:00,  6.43s/it, loss=43.3756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/72, Avg Loss: 4.2808, LR: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/72: 100%|██████████| 59/59 [06:17<00:00,  6.40s/it, loss=48.8049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/72, Avg Loss: 3.5413, LR: 0.000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/72: 100%|██████████| 59/59 [06:24<00:00,  6.52s/it, loss=46.4426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/72, Avg Loss: 3.7202, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/72: 100%|██████████| 59/59 [06:19<00:00,  6.43s/it, loss=51.2715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/72, Avg Loss: 3.7566, LR: 0.000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/72: 100%|██████████| 59/59 [06:25<00:00,  6.53s/it, loss=45.9105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/72, Avg Loss: 3.2820, LR: 0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/72: 100%|██████████| 59/59 [06:31<00:00,  6.64s/it, loss=46.8656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/72, Avg Loss: 3.3064, LR: 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/72: 100%|██████████| 59/59 [06:27<00:00,  6.57s/it, loss=46.0240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/72, Avg Loss: 3.0245, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/72: 100%|██████████| 59/59 [06:23<00:00,  6.50s/it, loss=46.1083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/72, Avg Loss: 3.1633, LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/72: 100%|██████████| 59/59 [06:20<00:00,  6.46s/it, loss=35.0895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/72, Avg Loss: 2.9498, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/72: 100%|██████████| 59/59 [06:13<00:00,  6.33s/it, loss=35.2567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/72, Avg Loss: 2.6575, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/72: 100%|██████████| 59/59 [06:14<00:00,  6.34s/it, loss=41.6189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/72, Avg Loss: 3.0068, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/72: 100%|██████████| 59/59 [06:18<00:00,  6.42s/it, loss=39.6657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/72, Avg Loss: 2.6984, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/72: 100%|██████████| 59/59 [06:18<00:00,  6.42s/it, loss=47.6295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/72, Avg Loss: 3.0418, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/72: 100%|██████████| 59/59 [06:14<00:00,  6.34s/it, loss=42.8130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/72, Avg Loss: 2.5625, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/72: 100%|██████████| 59/59 [06:25<00:00,  6.54s/it, loss=48.1212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/72, Avg Loss: 2.7559, LR: 0.000000\n",
      "\n",
      "✓ Model saved to jaguar_reid_model.pth\n",
      "Loading normalization from facebook/dinov2-base...\n",
      "  mean: [0.485, 0.456, 0.406]\n",
      "  std: [0.229, 0.224, 0.225]\n",
      "Found 371 test images\n",
      "\n",
      "Extracting test embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:05<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137270/137270 [00:03<00:00, 44111.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Submission saved to submission.csv\n",
      "  Rows: 137,270\n",
      "  Similarity range: [0.2723, 1.0000]\n",
      "  Similarity mean: 0.5121\n",
      "\n",
      "✓ Done!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Paths\n",
    "    TRAIN_CSV = 'jaguar-re-id/train.csv'\n",
    "    TRAIN_DIR = 'jaguar-re-id/train/train'\n",
    "    TEST_CSV = 'jaguar-re-id/test.csv'\n",
    "    TEST_DIR = 'jaguar-re-id/test/test'\n",
    "    OUTPUT_CSV = 'submission.csv'\n",
    "    MODEL_PATH = 'jaguar_reid_model.pth'\n",
    "    \n",
    "    # Hyperparameters (adjusted for MacOS)\n",
    "    NUM_EPOCHS = 72  # Reduced for faster training on CPU/MPS\n",
    "    BATCH_SIZE = 32  # Smaller batch size for memory\n",
    "    EMBEDDING_DIM = 512\n",
    "    LEARNING_RATE = 1e-4\n",
    "    \n",
    "    # Get best available device\n",
    "    DEVICE = get_device()\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(\n",
    "        train_csv=TRAIN_CSV,\n",
    "        train_dir=TRAIN_DIR,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        lr=LEARNING_RATE,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), MODEL_PATH)\n",
    "    print(f\"\\n✓ Model saved to {MODEL_PATH}\")\n",
    "    \n",
    "    # Extract test embeddings\n",
    "    embeddings_dict = extract_test_embeddings(model, TEST_DIR, device=DEVICE)\n",
    "    \n",
    "    # Create submission\n",
    "    submission = create_submission(embeddings_dict, TEST_CSV, OUTPUT_CSV)\n",
    "    \n",
    "    print(\"\\n✓ Done!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9540ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaguar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
